{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Hazard Tables\n",
    "This `Python` notebook creates hazard tables to use in cox regression. It creates one hazard table per block (so there is a matching data json file). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from helpers import retrace\n",
    "import json\n",
    "import copy\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_n_triangle_paths(M, edge):\n",
    "    \"\"\" Fast check for triangle closing rule\"\"\"\n",
    "    try:\n",
    "        from_neighbors = set(M[edge[0]])  # if concept 0 not in network, false\n",
    "        to_neighbors = set(M[edge[1]])  # if concept 1 not in network, false\n",
    "        return len(from_neighbors & to_neighbors)  # closes number of existing paths\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def instantaneous_hazard_factors(game, g, t):\n",
    "    \"\"\"\n",
    "    Given the state of the game, what are the factors influencing the hazard of adopting all beliefs?\n",
    "\n",
    "    Returns a row for the hazard factors of all individuals for adopting all beliefs \n",
    "    given the current state of the game. Gets big fast.\n",
    "    \"\"\"\n",
    "    prompt_nodes = set(game['data.clues']['tclue_1_2']['nodes'])\n",
    "\n",
    "    rows = []\n",
    "    for player_id, player_data in game['players'].items():\n",
    "\n",
    "        pos = player_data['data.position']\n",
    "        M = g.nodes()[player_id]['M']  # promising leads (memory)\n",
    "        F = g.nodes()[player_id]['F']  # dead ends (forgetory)\n",
    "\n",
    "        for clue_id, clue_data in game['data.clues'].items():\n",
    "            if clue_id[0] == pos[0]: # only collect treatment clues for treatment players & vice versa\n",
    "                \n",
    "                nodes = set(clue_data['nodes'])\n",
    "                row = {\n",
    "                    'start': t,\n",
    "                    \n",
    "                    'exposure_id': '%s_%s'%(player_id, clue_id),  # to group all rows corresponding to same exposure \n",
    "                    'player_id': player_id,  # player random effect\n",
    "                    'game_id': game['_id'],  # game random effect\n",
    "    \n",
    "                    'is_treatment_condition': pos.startswith('t'),\n",
    "                    'is_spoke': len(nodes.intersection(prompt_nodes)) == 1,\n",
    "                    'is_link_or_spur': len(nodes.intersection(prompt_nodes)) == 0,\n",
    "                    'is_prompt': nodes == prompt_nodes,\n",
    "                    'is_in_leads': M.has_edge(*nodes),\n",
    "                    'is_in_deads': F.has_edge(*nodes),\n",
    "                    \n",
    "                    'n_exposures': sum([g.nodes()[nid]['M'].has_edge(*nodes) for nid in g.neighbors(player_id)]),  # number of neighbors exposing\n",
    "\n",
    "                    # number of beliefs already adopted\n",
    "                    'n_existing_leads': M.number_of_edges(),\n",
    "                    \n",
    "                    # dummies for the time block\n",
    "                    'in_startup':    t<30,   # reading newly available clues\n",
    "                    'in_peak':   30<=t<180,  # most active time\n",
    "                    'in_tail':  180<=t<420,  # less active time\n",
    "                    'in_close': 420<=t,      # last minute, running out of time\n",
    "                    \n",
    "                    # number of connections by any clue to any of the rim nodes\n",
    "                    'n_rim_connections': sum([v for k,v in M.degree(nodes-prompt_nodes)]),  # includes the current clue, if it exists\n",
    "                    \n",
    "                    # number of triangle paths\n",
    "                    'n_triangle_paths': fast_n_triangle_paths(M, clue_data['nodes']),\n",
    "                    \n",
    "                    # number of beliefs that the player has that are also in the exposers' leads\n",
    "                    'n_shared_edges': len({\n",
    "                        edge for nid in g.neighbors(player_id) \n",
    "                        if g.nodes()[nid]['M'].has_edge(*nodes) \n",
    "                        for edge in g.nodes()[nid]['M'].edges()\n",
    "                    }.intersection({edge for edge in M.edges()})), \n",
    "                }\n",
    "                row['is_link'] = row['is_link_or_spur'] & row['is_treatment_condition']\n",
    "                row['is_spur'] = row['is_link_or_spur'] & ~row['is_treatment_condition']                \n",
    "                rows.append(row)\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "def process_exposure_group(group, t_last):\n",
    "    \"\"\"\n",
    "    Groups represent player-clue combinations, or unique \"exposure\" possibilities\n",
    "    Takes the hazard table and creates a table that lifelines can use.\n",
    "    1. Condenses multiple rows (by dropping duplicates)\n",
    "    2. Treats start and end times\n",
    "    3. Identifies adoption events\n",
    "    \"\"\"\n",
    "    \n",
    "    # discard player-clue groups where the player is never exposed to the clue\n",
    "    if max(group['n_exposures']) == 0: \n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # check that group is sorted\n",
    "    group.sort_values(['start'], inplace=True)\n",
    "    \n",
    "    # drop consecutive duplicate rows (ie, nothing changes w.r.t. the adoption factors)\n",
    "    match_on_cols = set(group.columns) - {'start'}\n",
    "    keep_rows = (group[match_on_cols].shift() != group[match_on_cols]).any(axis=1)\n",
    "    group = group.loc[keep_rows]\n",
    "\n",
    "    # identify exposures where the player is exposed at start\n",
    "    # the player may react differently to these than others\n",
    "    group['is_exposed_t0'] = (group[group['start']<3]['n_exposures'] > 0).any()\n",
    "    \n",
    "    # identify clues the player holds at start\n",
    "    group['is_held_t0'] = (group[group['start']<3]['is_in_leads']).any()\n",
    "\n",
    "    # add \"stop\" column\n",
    "    group['stop'] = group['start'].shift(-1)\n",
    "    group.loc[group.index[-1], 'stop'] = t_last\n",
    "    \n",
    "    # identify \"adopt\" events \n",
    "    # ie. the row period ends with an adoption change\n",
    "    group['adopt_event'] = group['is_in_leads'] < group.shift(-1)['is_in_leads']\n",
    "    group.loc[group.index[-1], 'adopt_event'] = False\n",
    "\n",
    "    # identify \"forget\" events\n",
    "    group['forget_event'] = group['is_in_leads'] > group.shift(-1)['is_in_leads']\n",
    "    group.loc[group.index[-1], 'forget_event'] = False\n",
    "\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_block(block_file):\n",
    "    with open(block_file, 'r') as f:\n",
    "        block = json.load(f)\n",
    "\n",
    "    block_collector = []\n",
    "    for name, game in block.items():\n",
    "        # game level constant calculations\n",
    "        t_final = datetime.strptime(game['finishedAt'], '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "        t_start = datetime.strptime(game['createdAt'], '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "        total_time = (t_final-t_start).total_seconds()\n",
    "        \n",
    "        # compute instantaneous hazard factors at each state change\n",
    "        hazard_factors_collector = []\n",
    "        for (active_player_id, g, t) in retrace(game):\n",
    "            hazard_factors_collector += instantaneous_hazard_factors(game, g, t)\n",
    "        hazard_factors = pd.DataFrame(hazard_factors_collector)\n",
    "        \n",
    "        # compute condensed hazard table\n",
    "        hazard_table_collector = []\n",
    "        for i, (eid, group) in enumerate(hazard_factors.groupby('exposure_id')):\n",
    "            hazard_table_collector.append(process_exposure_group(group, total_time))\n",
    "        hazard_table = pd.concat(hazard_table_collector)\n",
    "        hazard_table['is_caveman_game'] = 'caveman' in game['data.gameSetupId']\n",
    "        \n",
    "        block_collector.append(hazard_table)\n",
    "    \n",
    "    # assemble all games in block into single hazard table\n",
    "    block_hazard_table = pd.concat(block_collector)\n",
    "    \n",
    "    # force boolean types to numeric\n",
    "    block_hazard_table *= 1\n",
    "    \n",
    "    # write to file\n",
    "    block_hazard_table_file = block_file.replace('.json', '_hazards.csv')\n",
    "    block_hazard_table.to_csv(block_hazard_table_file)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../results-anonymized/experiment/block_9.json',\n",
       " '../results-anonymized/experiment/block_16.json',\n",
       " '../results-anonymized/experiment/block_20.json',\n",
       " '../results-anonymized/experiment/block_5.json',\n",
       " '../results-anonymized/experiment/block_4.json',\n",
       " '../results-anonymized/experiment/block_21.json',\n",
       " '../results-anonymized/experiment/block_17.json',\n",
       " '../results-anonymized/experiment/block_8.json',\n",
       " '../results-anonymized/experiment/block_26.json',\n",
       " '../results-anonymized/experiment/block_3.json',\n",
       " '../results-anonymized/experiment/block_10.json',\n",
       " '../results-anonymized/experiment/block_11.json',\n",
       " '../results-anonymized/experiment/block_2.json',\n",
       " '../results-anonymized/experiment/block_27.json',\n",
       " '../results-anonymized/experiment/block_1.json',\n",
       " '../results-anonymized/experiment/block_24.json',\n",
       " '../results-anonymized/experiment/block_12.json',\n",
       " '../results-anonymized/experiment/block_28.json',\n",
       " '../results-anonymized/experiment/block_29.json',\n",
       " '../results-anonymized/experiment/block_13.json',\n",
       " '../results-anonymized/experiment/block_25.json',\n",
       " '../results-anonymized/experiment/block_0.json',\n",
       " '../results-anonymized/experiment/block_14.json',\n",
       " '../results-anonymized/experiment/block_18.json',\n",
       " '../results-anonymized/experiment/block_7.json',\n",
       " '../results-anonymized/experiment/block_22.json',\n",
       " '../results-anonymized/experiment/block_23.json',\n",
       " '../results-anonymized/experiment/block_6.json',\n",
       " '../results-anonymized/experiment/block_19.json',\n",
       " '../results-anonymized/experiment/block_15.json']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"../results-anonymized/experiment/\"\n",
    "files = glob.glob(output_dir+'block_*.json')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../results-anonymized/experiment/block_9.json already processed\n",
      "../results-anonymized/experiment/block_16.json already processed\n",
      "../results-anonymized/experiment/block_20.json already processed\n",
      "../results-anonymized/experiment/block_5.json already processed\n",
      "../results-anonymized/experiment/block_4.json already processed\n",
      "../results-anonymized/experiment/block_21.json already processed\n",
      "../results-anonymized/experiment/block_17.json already processed\n",
      "../results-anonymized/experiment/block_8.json already processed\n",
      "['Bennet', \"in their early 20's\"] no longer in source 363Wtc9W7pHpCXn2n\n",
      "['Mitchell', 'a white Toyota Avalon'] no longer in source pxdEnxkB8c6zGXbot\n",
      "['a blue long sleeve shirt', 'a journalist uncovering a story'] no longer in source ktfhRNJT5GdPwZ6bk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:105: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:114: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a white Toyota Avalon', 'a broken axle'] no longer in source 7Z9tEGZ4mfgQEH5uR\n",
      "../results-anonymized/experiment/block_26.json complete\n",
      "../results-anonymized/experiment/block_3.json already processed\n",
      "../results-anonymized/experiment/block_10.json already processed\n",
      "../results-anonymized/experiment/block_11.json already processed\n",
      "../results-anonymized/experiment/block_2.json already processed\n",
      "../results-anonymized/experiment/block_27.json complete\n",
      "../results-anonymized/experiment/block_1.json already processed\n",
      "['Mills', 'the bracelet'] no longer in source XYDJ6XdbJrK3SoQXC\n",
      "['Roberts', 'a blue Chevrolet Corvette'] no longer in source 4nBtzav8tLCvp4nWd\n",
      "../results-anonymized/experiment/block_24.json complete\n",
      "../results-anonymized/experiment/block_12.json already processed\n",
      "['Bennet', 'a bear'] no longer in source Y7Pt2rrYEaPeDWTS3\n",
      "['a short man', 'a broken arm'] no longer in source GWFShkhDJWncK4bQo\n",
      "['a partially-bald man', 'the Dalhoff Estate'] no longer in source QHZcFHi4iKZp65jFr\n",
      "['a set of hex keys', 'circumvent a lock'] no longer in source QHZcFHi4iKZp65jFr\n",
      "['a black scarf', 'the Dalhoff Estate'] no longer in source qBPHQvrsWK8dKeKwp\n",
      "../results-anonymized/experiment/block_28.json complete\n",
      "../results-anonymized/experiment/block_29.json complete\n",
      "../results-anonymized/experiment/block_13.json already processed\n",
      "['a white Toyota Avalon', 'the art museum'] no longer in source b3AMyCfQo8zALtzWu\n",
      "['the necklace', 'a hacksaw'] no longer in source DNKwCGMBjaYNENjPs\n",
      "../results-anonymized/experiment/block_25.json complete\n",
      "../results-anonymized/experiment/block_0.json already processed\n",
      "../results-anonymized/experiment/block_14.json already processed\n",
      "../results-anonymized/experiment/block_18.json already processed\n",
      "../results-anonymized/experiment/block_7.json already processed\n",
      "../results-anonymized/experiment/block_22.json already processed\n",
      "../results-anonymized/experiment/block_23.json already processed\n",
      "../results-anonymized/experiment/block_6.json already processed\n",
      "../results-anonymized/experiment/block_19.json already processed\n",
      "../results-anonymized/experiment/block_15.json already processed\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "\n",
    "for file in files:\n",
    "    if not path.exists(file.replace('.json', '_hazards.csv')):\n",
    "        process_block(file)\n",
    "        print(file+\" complete\")\n",
    "    else:\n",
    "        print(file+\" already processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!say \"analysis complete\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
